{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2542b42-45a2-47a5-b9d2-0f36b7b981ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Data Source 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2359b983-fc9c-4741-856e-b6abfef3f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "# Replace <username> and <password> with your MongoDB Atlas credentials\n",
    "username = \"anuphap\"\n",
    "password = \"Pekpeping_29\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d4e8ba-0efd-4493-8048-5096397bae35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://mmlspark.azureedge.net/maven added as a remote repository with the name: repo-1\n",
      "Ivy Default Cache set to: /home/azureuser/.ivy2/cache\n",
      "The jars for the packages stored in: /home/azureuser/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      "com.microsoft.azure#spark-mssql-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9ccd2bf2-1988-45e6-8cab-14ad4c59c244;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark/spark-3.5.0-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      "\tfound com.microsoft.azure#spark-mssql-connector_2.12;1.2.0 in central\n",
      "\tfound com.microsoft.sqlserver#mssql-jdbc;8.4.1.jre8 in central\n",
      ":: resolution report :: resolve 252ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\tcom.microsoft.azure#spark-mssql-connector_2.12;1.2.0 from central in [default]\n",
      "\tcom.microsoft.sqlserver#mssql-jdbc;8.4.1.jre8 from central in [default]\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   6   |   0   |   0   |   0   ||   6   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9ccd2bf2-1988-45e6-8cab-14ad4c59c244\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 6 already retrieved (0kB/7ms)\n",
      "24/02/13 01:47:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark sessions\n",
    "spark = SparkSession.builder.appName(\"Assignment1\")\\\n",
    "                            .config(\"spark.driver.extraClassPath\", \"mariadb-java-client-3.3.2.jar\") \\\n",
    "                            .config(\"spark.mongodb.input.uri\", f\"mongodb+srv://anuphap:Pekpeping_29@cluster0.umpanj8.mongodb.net\") \\\n",
    "                            .config(\"spark.mongodb.input.database\", \"sample_supplies\") \\\n",
    "                            .config(\"spark.mongodb.input.collection\", \"sales\") \\\n",
    "                            .config(\"spark.mongodb.output.uri\", f\"mongodb+srv://anuphap:Pekpeping_29@cluster0.umpanj8.mongodb.net\") \\\n",
    "                            .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1,com.microsoft.azure:spark-mssql-connector_2.12:1.2.0\") \\\n",
    "                            .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\") \\\n",
    "                            .master(\"local\")\\\n",
    "                            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925aebea-92fd-4701-879e-fca1819bedd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Source 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6dd7249-2e99-4920-82a7-c1a5c0dbfab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load CSV files into PySpark DataFrames\n",
    "brands_df = spark.read.csv(\"hdfs://localhost:9000/user/input/bike_store/brands_cleaned.csv\", header=True)\n",
    "categories_df = spark.read.csv(\"hdfs://localhost:9000/user/input/bike_store/categories_cleaned.csv\", header=True)\n",
    "customers_df = spark.read.csv(\"hdfs://localhost:9000/user/input/bike_store/customers_cleaned.csv\", header=True)\n",
    "orders_items_df = spark.read.csv(\"hdfs://localhost:9000/user/input/bike_store/order_items_cleaned.csv\", header=True)\n",
    "orders_df = spark.read.csv(\"hdfs://localhost:9000/user/input/bike_store/orders_cleaned.csv\", header=True)\n",
    "products_df = spark.read.csv(\"hdfs://localhost:9000/user/input/bike_store/products_cleaned.csv\", header=True)\n",
    "staffs_df = spark.read.csv(\"hdfs://localhost:9000/user/input/bike_store/staffs_cleaned.csv\", header=True)\n",
    "stores_df = spark.read.csv(\"hdfs://localhost:9000/user/input/bike_store/stores_cleaned.csv\", header=True)\n",
    "stocks_df = spark.read.csv(\"hdfs://localhost:9000/user/input/bike_store/stocks_cleaned.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfd7a19f-e850-4469-81bb-0918a128e4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers:\n",
      "+-----------+----------+---------+--------------+--------------------+--------------------+---------------+-----+--------+\n",
      "|customer_id|first_name|last_name|         phone|               email|              street|           city|state|zip_code|\n",
      "+-----------+----------+---------+--------------+--------------------+--------------------+---------------+-----+--------+\n",
      "|          1|     Debra|    Burks|          NULL|debra.burks@yahoo...|    9273 Thorne Ave.|   Orchard Park|   NY|   14127|\n",
      "|          2|     Kasha|     Todd|          NULL|kasha.todd@yahoo.com|     910 Vine Street|       Campbell|   CA|   95008|\n",
      "|          3|    Tameka|   Fisher|          NULL|tameka.fisher@aol...|769C Honey Creek St.|  Redondo Beach|   CA|   90278|\n",
      "|          4|     Daryl|   Spence|          NULL|daryl.spence@aol.com|      988 Pearl Lane|      Uniondale|   NY|   11553|\n",
      "|          5|Charolette|     Rice|(916) 381-6003|charolette.rice@m...|       107 River Dr.|     Sacramento|   CA|   95820|\n",
      "|          6|   Lyndsey|     Bean|          NULL|lyndsey.bean@hotm...|       769 West Road|       Fairport|   NY|   14450|\n",
      "|          7|   Latasha|     Hays|(716) 986-3359|latasha.hays@hotm...|7014 Manor Statio...|        Buffalo|   NY|   14215|\n",
      "|          8| Jacquline|   Duncan|          NULL|jacquline.duncan@...|        15 Brown St.|Jackson Heights|   NY|   11372|\n",
      "|          9|  Genoveva|  Baldwin|          NULL|genoveva.baldwin@...|   8550 Spruce Drive|Port Washington|   NY|   11050|\n",
      "|         10|   Pamelia|   Newman|          NULL|pamelia.newman@gm...|   476 Chestnut Ave.|         Monroe|   NY|   10950|\n",
      "|         11|   Deshawn|  Mendoza|          NULL|deshawn.mendoza@y...|8790 Cobblestone ...|         Monsey|   NY|   10952|\n",
      "|         12|     Robby|    Sykes|(516) 583-7761|robby.sykes@hotma...|486 Rock Maple St...|      Hempstead|   NY|   11550|\n",
      "|         13|   Lashawn|    Ortiz|          NULL|lashawn.ortiz@msn...|   27 Washington Rd.|       Longview|   TX|   75604|\n",
      "|         14|     Garry| Espinoza|          NULL|garry.espinoza@ho...| 7858 Rockaway Court|         Forney|   TX|   75126|\n",
      "|         15|    Linnie|   Branch|          NULL|linnie.branch@gma...|314 South Columbi...|    Plattsburgh|   NY|   12901|\n",
      "|         16|    Emmitt|  Sanchez|(212) 945-8823|emmitt.sanchez@ho...|461 Squaw Creek Road|       New York|   NY|   10002|\n",
      "|         17|     Caren| Stephens|          NULL|caren.stephens@ms...|       914 Brook St.|      Scarsdale|   NY|   10583|\n",
      "|         18| Georgetta|   Hardin|          NULL|georgetta.hardin@...|      474 Chapel Dr.|    Canandaigua|   NY|   14424|\n",
      "|         19|  Lizzette|    Stein|          NULL|lizzette.stein@ya...|  19 Green Hill Lane|   Orchard Park|   NY|   14127|\n",
      "|         20|     Aleta|  Shepard|          NULL|aleta.shepard@aol...|      684 Howard St.|     Sugar Land|   TX|   77478|\n",
      "+-----------+----------+---------+--------------+--------------------+--------------------+---------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Staff:\n",
      "+--------+----------+---------+--------------------+--------------+------+--------+----------+\n",
      "|staff_id|first_name|last_name|               email|         phone|active|store_id|manager_id|\n",
      "+--------+----------+---------+--------------------+--------------+------+--------+----------+\n",
      "|       1|   Fabiola|  Jackson|fabiola.jackson@b...|(831) 555-5554|     1|       1|      NULL|\n",
      "|       2|    Mireya| Copeland|mireya.copeland@b...|(831) 555-5555|     1|       1|         1|\n",
      "|       3|     Genna|  Serrano|genna.serrano@bik...|(831) 555-5556|     1|       1|         2|\n",
      "|       4|    Virgie|  Wiggins|virgie.wiggins@bi...|(831) 555-5557|     1|       1|         2|\n",
      "|       5|  Jannette|    David|jannette.david@bi...|(516) 379-4444|     1|       2|         1|\n",
      "|       6| Marcelene|    Boyer|marcelene.boyer@b...|(516) 379-4445|     1|       2|         5|\n",
      "|       7|    Venita|   Daniel|venita.daniel@bik...|(516) 379-4446|     1|       2|         5|\n",
      "|       8|      Kali|   Vargas|kali.vargas@bikes...|(972) 530-5555|     1|       3|         1|\n",
      "|       9|     Layla|  Terrell|layla.terrell@bik...|(972) 530-5556|     1|       3|         7|\n",
      "|      10|Bernardine|  Houston|bernardine.housto...|(972) 530-5557|     1|       3|         7|\n",
      "+--------+----------+---------+--------------------+--------------+------+--------+----------+\n",
      "\n",
      "Orders:\n",
      "+--------+-----------+------------+----------+-------------+------------+--------+--------+\n",
      "|order_id|customer_id|order_status|order_date|required_date|shipped_date|store_id|staff_id|\n",
      "+--------+-----------+------------+----------+-------------+------------+--------+--------+\n",
      "|       1|        259|   Completed|2016-01-01|   2016-01-03|  2016-01-03|       1|       2|\n",
      "|       2|       1212|   Completed|2016-01-01|   2016-01-04|  2016-01-03|       2|       6|\n",
      "|       3|        523|   Completed|2016-01-02|   2016-01-05|  2016-01-03|       2|       7|\n",
      "|       4|        175|   Completed|2016-01-03|   2016-01-04|  2016-01-05|       1|       3|\n",
      "|       5|       1324|   Completed|2016-01-03|   2016-01-06|  2016-01-06|       2|       6|\n",
      "|       6|         94|   Completed|2016-01-04|   2016-01-07|  2016-01-05|       2|       6|\n",
      "|       7|        324|   Completed|2016-01-04|   2016-01-07|  2016-01-05|       2|       6|\n",
      "|       8|       1204|   Completed|2016-01-04|   2016-01-05|  2016-01-05|       2|       7|\n",
      "|       9|         60|   Completed|2016-01-05|   2016-01-08|  2016-01-08|       1|       2|\n",
      "|      10|        442|   Completed|2016-01-05|   2016-01-06|  2016-01-06|       2|       6|\n",
      "|      11|       1326|   Completed|2016-01-05|   2016-01-08|  2016-01-07|       2|       7|\n",
      "|      12|         91|   Completed|2016-01-06|   2016-01-08|  2016-01-09|       1|       2|\n",
      "|      13|        873|   Completed|2016-01-08|   2016-01-11|  2016-01-11|       2|       6|\n",
      "|      14|        258|   Completed|2016-01-09|   2016-01-11|  2016-01-12|       1|       3|\n",
      "|      15|        450|   Completed|2016-01-09|   2016-01-10|  2016-01-12|       2|       7|\n",
      "|      16|        552|   Completed|2016-01-12|   2016-01-15|  2016-01-15|       1|       3|\n",
      "|      17|       1175|   Completed|2016-01-12|   2016-01-14|  2016-01-14|       1|       3|\n",
      "|      18|        541|   Completed|2016-01-14|   2016-01-17|  2016-01-15|       1|       3|\n",
      "|      19|        696|   Completed|2016-01-14|   2016-01-17|  2016-01-16|       1|       2|\n",
      "|      20|        923|   Completed|2016-01-14|   2016-01-16|  2016-01-17|       1|       2|\n",
      "+--------+-----------+------------+----------+-------------+------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Order Items:\n",
      "+--------+-------+----------+--------+----------+--------+-----------+--------------+----------------------+\n",
      "|order_id|item_id|product_id|quantity|list_price|discount|total_price|total_discount|total_price_discounted|\n",
      "+--------+-------+----------+--------+----------+--------+-----------+--------------+----------------------+\n",
      "|       1|      1|        20|       1|    599.99|     0.2|     599.99|       119.998|               479.992|\n",
      "|       1|      2|         8|       2|   1799.99|    0.07|    3599.98|      251.9986|             3347.9814|\n",
      "|       1|      3|        10|       2|      1549|    0.05|       3098|         154.9|                2943.1|\n",
      "|       1|      4|        16|       2|    599.99|    0.05|    1199.98|        59.999|              1139.981|\n",
      "|       1|      5|         4|       1|   2899.99|     0.2|    2899.99|       579.998|              2319.992|\n",
      "|       2|      1|        20|       1|    599.99|    0.07|     599.99|       41.9993|              557.9907|\n",
      "|       2|      2|        16|       2|    599.99|    0.05|    1199.98|        59.999|              1139.981|\n",
      "|       3|      1|         3|       1|    999.99|    0.05|     999.99|       49.9995|              949.9905|\n",
      "|       3|      2|        20|       1|    599.99|    0.05|     599.99|       29.9995|              569.9905|\n",
      "|       4|      1|         2|       2|    749.99|     0.1|    1499.98|       149.998|              1349.982|\n",
      "|       5|      1|        10|       2|      1549|    0.05|       3098|         154.9|                2943.1|\n",
      "|       5|      2|        17|       1|       429|    0.07|        429|         30.03|                398.97|\n",
      "|       5|      3|        26|       1|    599.99|    0.07|     599.99|       41.9993|              557.9907|\n",
      "|       6|      1|        18|       1|       449|    0.07|        449|         31.43|                417.57|\n",
      "|       6|      2|        12|       2|    549.99|    0.05|    1099.98|        54.999|              1044.981|\n",
      "|       6|      3|        20|       1|    599.99|     0.1|     599.99|        59.999|               539.991|\n",
      "|       6|      4|         3|       2|    999.99|    0.07|    1999.98|      139.9986|             1859.9814|\n",
      "|       6|      5|         9|       2|   2999.99|    0.07|    5999.98|      419.9986|             5579.9814|\n",
      "|       7|      1|        15|       1|    529.99|    0.07|     529.99|       37.0993|              492.8907|\n",
      "|       7|      2|         3|       1|    999.99|     0.1|     999.99|        99.999|               899.991|\n",
      "+--------+-------+----------+--------+----------+--------+-----------+--------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total Sales per Customer:\n",
      "+------------------+------------------+\n",
      "|              city|      totals_sales|\n",
      "+------------------+------------------+\n",
      "|            Corona|        13994.9706|\n",
      "|            Auburn|10063.074900000001|\n",
      "|           Baldwin|51380.904299999995|\n",
      "|         Levittown|24056.256999999998|\n",
      "|            Monroe| 84076.36329999998|\n",
      "|       Lindenhurst|         27274.366|\n",
      "|           Atwater|25460.840999999993|\n",
      "|         Bay Shore|        62345.5418|\n",
      "|         Rego Park|10843.046899999998|\n",
      "|     Central Islip| 77520.74409999997|\n",
      "|Huntington Station| 65140.41950000002|\n",
      "|           Anaheim|        44855.2655|\n",
      "|   Jackson Heights| 39536.58429999999|\n",
      "|           Bayside|29026.505599999997|\n",
      "|         Yuba City| 6450.952899999999|\n",
      "|           Commack|         9448.0482|\n",
      "|           Oakland|35442.094900000004|\n",
      "|         Oceanside|        27610.4973|\n",
      "|          New City|17761.335399999993|\n",
      "|          Holbrook|15250.474500000002|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Customers:\")\n",
    "customers_df.show()\n",
    "\n",
    "print(\"Staff:\")\n",
    "staffs_df.show()\n",
    "\n",
    "print(\"Orders:\")\n",
    "orders_df.show()\n",
    "\n",
    "print(\"Order Items:\")\n",
    "orders_items_df.show()\n",
    "\n",
    "# Joining the DataFrames and calculating total sales per customer\n",
    "joined_ord_df = orders_df.join(customers_df, \"customer_id\", \"inner\")\n",
    "joined_item_df = joined_ord_df.join(orders_items_df, \"order_id\", \"inner\")\n",
    "total_sales_per_customer = joined_item_df.groupBy(\"city\").agg(F.sum(\"total_price_discounted\").alias(\"totals_sales\"))\n",
    "\n",
    "print(\"Total Sales per Customer:\")\n",
    "total_sales_per_customer.show()\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas DataFrame for further analysis\n",
    "# total_sales_pd = total_sales_per_customer.toPandas()\n",
    "\n",
    "# Stop the Spark session\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956879e4-74d2-4535-8a2d-249375f4741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Source 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e324dce-22fa-44fa-aca4-37f74fdb2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"localhost\"\n",
    "port = 3306\n",
    "database = \"classicmodels\"\n",
    "jdbc_url = f\"jdbc:mysql://{server}:{port}/{database}?permitMysqlScheme\"\n",
    "\n",
    "\n",
    "user = \"root\"\n",
    "password = \"test1234\"\n",
    "jdbc_driver = \"org.mariadb.jdbc.Driver\"\n",
    "\n",
    "properties = {\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"driver\": jdbc_driver\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9201606-5dca-4577-873a-1e81c8386d05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orders_df = spark.read.jdbc(jdbc_url, \"(select * from orders) tab\", properties=properties)\n",
    "customers_df = spark.read.jdbc(jdbc_url, \"(select * from customers) tab\", properties=properties)\n",
    "orderdetails_df = spark.read.jdbc(jdbc_url, \"(select * from orderdetails) tab\", properties=properties)\n",
    "employees_df = spark.read.jdbc(jdbc_url, \"(select * from employees) tab\", properties=properties)\n",
    "offices_df = spark.read.jdbc(jdbc_url, \"(select * from offices) tab\", properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bece1324-acbe-49a9-b5ae-db05b769fd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|         city|total_sales|\n",
      "+-------------+-----------+\n",
      "|San Francisco|      15910|\n",
      "|       London|      15691|\n",
      "|        Tokyo|       4923|\n",
      "|       Sydney|      12878|\n",
      "|        Paris|      33887|\n",
      "|       Boston|       9788|\n",
      "|          NYC|      12439|\n",
      "+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_df = orders_df.join(customers_df, orders_df.customerNumber == customers_df.customerNumber) \\\n",
    "    .join(orderdetails_df, orders_df.orderNumber == orderdetails_df.orderNumber) \\\n",
    "    .join(employees_df, customers_df.salesRepEmployeeNumber == employees_df.employeeNumber) \\\n",
    "    .join(offices_df, employees_df.officeCode == offices_df.officeCode) \\\n",
    "    .groupBy(offices_df.city) \\\n",
    "    .agg(sum(orderdetails_df.quantityOrdered).alias(\"total_sales\"))\n",
    "    \n",
    "res_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "476f733f-3724-41b2-9e8e-7db7e4dfa60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Data Source 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cc7b1a7-0c8e-4781-99b7-4382a5cd521f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sales_df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\", \"mongodb+srv://student:student@cluster0.koi0v.mongodb.net/sample_supplies.sales\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7e37db5-1c91-4d51-b15a-79b8859ed397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------+-------+\n",
      "|                item| price|quantity|  Sales|\n",
      "+--------------------+------+--------+-------+\n",
      "|{printer paper, 1...| 17.35|       7| 121.45|\n",
      "|{envelopes, 21.41...| 21.41|       9| 192.69|\n",
      "|{binder, 20.04, 8...| 20.04|       8| 160.32|\n",
      "|{pens, 56.62, 4, ...| 56.62|       4| 226.48|\n",
      "|{laptop, 495.79, ...|495.79|       4|1983.16|\n",
      "|{pens, 57.03, 2, ...| 57.03|       2| 114.06|\n",
      "|{backpack, 87.85,...| 87.85|       1|  87.85|\n",
      "|{envelopes, 23.53...| 23.53|       6| 141.18|\n",
      "|{envelopes, 10.13...| 10.13|       6|  60.78|\n",
      "|{binder, 11.57, 9...| 11.57|       9| 104.13|\n",
      "|{pens, 41.45, 2, ...| 41.45|       2|  82.90|\n",
      "|{printer paper, 1...| 18.47|      10| 184.70|\n",
      "|{backpack, 56.04,...| 56.04|       3| 168.12|\n",
      "|{binder, 24.46, 4...| 24.46|       4|  97.84|\n",
      "|{notepad, 24.00, ...| 24.00|       5| 120.00|\n",
      "|{pens, 58.81, 2, ...| 58.81|       2| 117.62|\n",
      "|{laptop, 548.20, ...|548.20|       3|1644.60|\n",
      "|{envelopes, 7.73,...|  7.73|       4|  30.92|\n",
      "|{printer paper, 2...| 27.51|       2|  55.02|\n",
      "|{notepad, 5.02, 1...|  5.02|       1|   5.02|\n",
      "+--------------------+------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explode the items array to have each item in a separate row\n",
    "exploded_sales_df = sales_df.select(explode(\"items\").alias(\"item\"))\n",
    "\n",
    "# Calculate sales for each item\n",
    "total_top_sales = exploded_sales_df.withColumn(\"price\", col(\"item.price\").cast(\"decimal(10,2)\")) \\\n",
    "                                    .withColumn(\"quantity\", col(\"item.quantity\").cast(\"integer\")) \\\n",
    "                                    .withColumn(\"Sales\", expr(\"price * quantity\"))\n",
    "# Show the resulting DataFrame\n",
    "total_top_sales.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bd54026-8eec-421c-9340-b2a4e11d4794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- price: decimal(6,2) (nullable = true)\n",
      " |    |-- quantity: integer (nullable = true)\n",
      " |    |-- tags: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- price: decimal(10,2) (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- Sales: decimal(21,2) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the schema of the DataFrame\n",
    "total_top_sales.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ded9504-38d3-4eb8-909a-53555c5d2128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-----------+\n",
      "|storeLocation|total_sales|sales_count|\n",
      "+-------------+-----------+-----------+\n",
      "|       Denver|  604839.59|       1549|\n",
      "|      Seattle|  418471.11|       1134|\n",
      "|       London|  307393.75|        794|\n",
      "|       Austin|  232942.75|        676|\n",
      "|     New York|  179766.71|        501|\n",
      "|    San Diego|  131922.67|        346|\n",
      "+-------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "# Add a unique ID column to total_top_sales DataFrame\n",
    "total_top_sales_with_id = total_top_sales.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "# Add a unique ID column to sales_df DataFrame\n",
    "sales_df_with_id = sales_df.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "# Join total_top_sales_with_id with sales_df_with_id on the generated ID\n",
    "joined_df = total_top_sales_with_id.join(sales_df_with_id.select(\"id\", \"storeLocation\"), \"id\", \"inner\")\n",
    "\n",
    "# Group by storeLocation and sum up the total sales\n",
    "top_sales_df = joined_df.groupBy(\"storeLocation\").agg(\n",
    "        sum(\"Sales\").alias(\"total_sales\"),\n",
    "        count(\"Sales\").alias(\"sales_count\")\n",
    "    )\n",
    "\n",
    "\n",
    "# Sort the DataFrame by total_sales in descending order\n",
    "sorted_sales_count_df = top_sales_df.orderBy(desc(\"total_sales\"))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "sorted_sales_count_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98ab5e9d-8c7c-4742-b9d9-923592b59d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Source 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2291f0d1-93e9-4210-9b43-ac0e7dbdb10e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+\n",
      "|              city|    totals_sales|\n",
      "+------------------+----------------+\n",
      "|            Corona| 13994.970703125|\n",
      "|            Auburn|10063.0751953125|\n",
      "|           Baldwin|     51380.90625|\n",
      "|         Levittown|   24056.2578125|\n",
      "|            Monroe|   84076.3671875|\n",
      "|       Lindenhurst| 27274.365234375|\n",
      "|           Atwater| 25460.841796875|\n",
      "|         Bay Shore|  62345.54296875|\n",
      "|         Rego Park|    10843.046875|\n",
      "|     Central Islip|   77520.7421875|\n",
      "|Huntington Station|  65140.41796875|\n",
      "|           Anaheim|    44855.265625|\n",
      "|   Jackson Heights|   39536.5859375|\n",
      "|           Bayside| 29026.505859375|\n",
      "|         Yuba City|     6450.953125|\n",
      "|           Commack| 9448.0478515625|\n",
      "|           Oakland|     35442.09375|\n",
      "|         Oceanside| 27610.498046875|\n",
      "|          New City|   17761.3359375|\n",
      "|          Holbrook| 15250.474609375|\n",
      "+------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "server_name = \"jdbc:sqlserver://bdgroup1server.database.windows.net\"\n",
    "database_name = \"myfirstdatabase\"\n",
    "url = server_name + \";\" + \"databaseName=\" + database_name + \";\"\n",
    "table_name = \"[dbo].[bikestore-group-city]\"\n",
    "jdbcDF = spark.read\\\n",
    ".format(\"com.microsoft.sqlserver.jdbc.spark\")\\\n",
    ".option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\\\n",
    ".option(\"url\", url)\\\n",
    ".option(\"dbtable\", table_name)\\\n",
    ".option(\"user\", \"azureuser\")\\\n",
    ".option(\"password\", \"Ilove85workWonder69\").load()\n",
    "\n",
    "jdbcDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "146dc7e2-b141-4a52-89a5-274fe0e5e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Union Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd1ce3a1-a8e3-4427-b215-3b0c7682d899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|              city|      totals_sales|\n",
      "+------------------+------------------+\n",
      "|            Corona|        13994.9706|\n",
      "|            Auburn|10063.074900000001|\n",
      "|           Baldwin|51380.904299999995|\n",
      "|         Levittown|24056.256999999998|\n",
      "|            Monroe| 84076.36329999998|\n",
      "|       Lindenhurst|         27274.366|\n",
      "|           Atwater|25460.840999999993|\n",
      "|         Bay Shore|        62345.5418|\n",
      "|         Rego Park|10843.046899999998|\n",
      "|     Central Islip| 77520.74409999997|\n",
      "|Huntington Station| 65140.41950000002|\n",
      "|           Anaheim|        44855.2655|\n",
      "|   Jackson Heights| 39536.58429999999|\n",
      "|           Bayside|29026.505599999997|\n",
      "|         Yuba City| 6450.952899999999|\n",
      "|           Commack|         9448.0482|\n",
      "|           Oakland|35442.094900000004|\n",
      "|         Oceanside|        27610.4973|\n",
      "|          New City|17761.335399999993|\n",
      "|          Holbrook|15250.474500000002|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# total_sales_per_customer data source 1\n",
    "# res_df data source 2\n",
    "# sorted_sales_count_df data source 3\n",
    "# jdbcDF data source 4\n",
    "\n",
    "combined_df = total_sales_per_customer.union(res_df).union(jdbcDF) #ds1 + ds2 + ds4\n",
    "combined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d094246f-4843-439f-b00f-ed8b685af146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to Azure SQL Database\n",
    "mode = \"overwrite\"  # or \"append\" if you want to append data to an existing table\n",
    "\n",
    "\n",
    "combined_df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"dbtable\", \"combinesales\") \\\n",
    "    .option(\"user\", \"azureuser\") \\\n",
    "    .option(\"password\", \"Ilove85workWonder69\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .mode(mode)\\\n",
    "    .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b51c233-edd2-4004-ad6c-aed40bc71ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 194:=================================================>   (257 + 1) / 276]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+-------------+-----------+-----------+\n",
      "|     city|      totals_sales|storeLocation|total_sales|sales_count|\n",
      "+---------+------------------+-------------+-----------+-----------+\n",
      "|San Diego|28511.119099999993|    San Diego|  131922.67|        346|\n",
      "| New York| 56729.15999999999|     New York|  179766.71|        501|\n",
      "|   London|           15691.0|       London|  307393.75|        794|\n",
      "|San Diego|   28511.119140625|    San Diego|  131922.67|        346|\n",
      "| New York|    56729.16015625|     New York|  179766.71|        501|\n",
      "+---------+------------------+-------------+-----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Result Data Frame = combined_df join sorted_sales_count_df (ds3)\n",
    "result_df = combined_df.join(sorted_sales_count_df, combined_df.city == sorted_sales_count_df.storeLocation)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5f85f32-4605-4e74-8678-e5cf9b402e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write Result to Azure SQL\n",
    "result_df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"dbtable\", \"resultsales\") \\\n",
    "    .option(\"user\", \"azureuser\") \\\n",
    "    .option(\"password\", \"Ilove85workWonder69\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .mode(mode)\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ec128e8-2465-41f9-adf9-74811d5e03d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8935d58-0072-486f-94b3-7e89db4bdf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
